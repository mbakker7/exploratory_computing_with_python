{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://raw.githubusercontent.com/mbakker7/exploratory_computing_with_python/master/tudelft_logo.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Exploratory Computing with Python\n",
    "*Developed by Mark Bakker*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 10: Continuous random variables\n",
    "In this notebook we deal with continuous distributions. We start with analyzing data that we generate ourselves, and we will consider real data at the end of this Notebook.\n",
    "\n",
    "The most common probability distribution is probably (no pun intended) the Normal distribution. Random numbers from a Normal distribution may be generated with the `normal` function in the `random` subpackage of `numpy`, where the keyword `loc` is the mean (default is 0) and `scale` is the standard deviation (default is 1).  The mean and standard deviation of a dataset can be computed with the functions `mean` and `std` of the `numpy` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rnd.normal(loc=5, scale=2, size=100)  # Array with 100 values\n",
    "print('mean of data: ', np.mean(data))\n",
    "print('standard deviation of data: ', np.std(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mean and standard deviation of the 100 numbers drawn from a normal distribution with mean 5 and standard deviation 2 are not exactly equal to 5 and 2, respectively. These are, after all, only estimates of the true underlying mean and standard deviation. These estimates are called the sample mean and sample standard deviation (of 100 numbers drawn from a Normal distribution). Run the above code several times. Each time, a new set of 100 random numbers is drawn, with a slightly different mean and standard deviation. We'll get back to that later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "Probably the first things to do when you obtain a new data set, is to look at the data. One way to do that is to draw a histogram. For a histogram, you count how many data points fall within a certain interval. For example, how many data points are between 5 and 6. These intervals are called bins. The bar graph of the number of data points in each bin is called a histogram. The function to compute and plot a histogram is called `hist` and is part of the `matplotlib` package. The simplest way of plotting a histogram is to let `hist` decide what bins to use; the default number of bins is `nbin=10`; `hist` even figures out where to put the limits of the bins. The `hist` function creates a histogram graph and returns a tuple of three items. The first item is an array of length `nbin` with the number of data points in each bin. The second item is an array of length `nbin+1` with the limits of the bins. The third item is a list of objects that represent the bars of the histogram; we won't use this last item here. \n",
    "\n",
    "In the code cell below, we make a histogram of 100 points drawn from a Normal distribution with mean 6 and standard deviation 2. Note that with a dataset of 100 points, the histogram doesn't look too much like the typical bell-shaped curve of a Normal distribution, even though the data points are actually drawn from a real Normal distribution. Run the code below several times to see how it changes with a new random set of 100 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rnd.normal(loc=6, scale=2, size=100)\n",
    "hist_data = plt.hist(data)\n",
    "plt.xlabel('bins')\n",
    "plt.ylabel('number of data points')\n",
    "print('number of data points in each bin:', hist_data[0])\n",
    "print('limits of the bins:', hist_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the previous example, the limits of the bins are not chosen as nice numbers: `hist` takes the minimum and maximum value of the data and divides it in `nbin` equal intervals. You normally want to specify the number of bins with the `bins` keyword, and the range (minimum and maximum limits of the bins) with the `range` keyword. If data values are outside this range (these may or may not be outliers), they are ignored. In the code below, 12 bins are chosen equally spaced from 0 to 12. Note that we use the same date as for the graph above, but by simply choosing different bins the histogram looks quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = plt.hist(data, bins=12, range=(0, 12))\n",
    "print('number of data points in each bin:', hist_data[0])\n",
    "print('limits of the bins:', hist_data[1])\n",
    "plt.xlabel('bins')\n",
    "plt.ylabel('number of data points');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line representing the probability density function of the underlying normal distribution may be added as follows. First import the `norm` class from the `scipy.stats` package. Then call the `norm.pdf` function (pdf stands for probability density function) to compute the values of the normal distribution given three arguments: the $x$ values where to compute the normal distribution, the mean, and the standard deviation. Let's add the underlying Normal distribution to the histogram we just created. The one thing we have to change in the histogram is the vertical axis. In the graph above, the vertical axis shows the number of data points. We need to normalize this so that the vertical axis gives the probability that a data point lies in a bin. The histogram may be normalized by specifying the `density=True` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "a = plt.hist(data, bins=12, range=(0, 12), density=True)\n",
    "x = np.linspace(0, 12, 100)\n",
    "y = norm.pdf(x, loc=6, scale=2) # mu=6, sig=2\n",
    "plt.plot(x, y, 'r')\n",
    "plt.xlabel('value')\n",
    "plt.ylabel('probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: <a name=\"back1\"></a>First histogram\n",
    "Generate 1000 random numbers from a Normal distribution with mean 100 and standard deviation 10. Compute and print to the screen the mean and standard deviation of your data. Create two graphs above each other using the `plt.subplot` command. In the top graph, plot a histogram using 20 bins going from 50 to 150. Note that with this size of a data set (1000 data points), the histogram starts to look a lot more like the typical bell-shaped curve of a Normal distribution. Add a red line representing the probability density function of the underlying normal distribution to the graph. In the bottom graph, draw a histogram of the cumulative distribution function, by setting the keyword `cumulative=True` (see `plt.hist?` for details). For the latter graph, use the keyword `align='right'` so that the bars are centered on the right bin edges (so that the line you are drawing next will approximately go through the centers of the bars). Add a red line representing the cumulative distribution function of the underlying normal distribution to the graph using the `norm.cdf` function, which works the same as the `norm.pdf` function but computes the cumulative distribution function (cdf). Finally, make sure the limits along the horizontal axis are the same for both graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ex1answer\">Answers to Exercise 1</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles\n",
    "Another useful description of a dataset are the quantiles. Quantiles are computed using ordered data (in ascending order). The 25 quantile is the data point in the ordered data such that 25% of the data is below this datapoint (and thus 75% is above this datapoint). The quantiles of a dataset are commonly referred to as the 'empirical quantiles' as they are the quantiles of the dataset, not of the underlying distribution. Quantiles are specified from 0 (0%) to 1 (100%). The 0.5 empirical quantile is equivalent to the median of the data. Common intervals to look at are the 50% region around the median (also called the interquartile range or IQR), which runs from the 0.25 empirical quantile to the 0.75 empirical quantile, and the 95% region, which runs from the 0.025 empirical quantile to the 0.975 empirical quantile. Quantiles of a dataset may be computed with the `quantile` function in the `numpy` package. The first argument is the data, the second argument is a list of quantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rnd.normal(loc=10, scale=2, size=100)\n",
    "lower, median, upper = np.quantile(data, [0.025, 0.5, 0.975])\n",
    "print('0.025 quantile:', lower)\n",
    "print('0.5 quantile:', median)\n",
    "print('0.975 quantile:', upper)\n",
    "print('95% interval:', lower, ' to ', upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretical quantiles of a given distribution may be computed with the `ppf` function (for percentage point function - odd name). For example, the theoretical values for the Normal distribution used above are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf([0.025, 0.5, 0.975], loc=10, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expercise 2. <a name=\"back2\"></a>Lower and upper quartile\n",
    "Generate 100 data points from a normal distribution with a mean of 20 and a standard deviation of 4. Compute the interquartile range (25%-75% range). Compute the theoretical value of the interquartile range and compare it to the interquartile range of the data. Draw a histogram of the cumulative distribution. Add red vertical lines to your graph for the 0.25 and 0.75 empirical quantiles of the data, and black vertical lines for the 0.25 and 0.75 quantiles of the underlying distribution. Vertical lines that span the graph may be added with the `plt.axvline` function, which takes the $x$ value of the line as an argument. To specify the color of the vertical line, use the `color` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ex2answer\">Answers to Exercise 2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-whisker plots\n",
    "Box-whisker plots (also simply referred to as boxplots) are a way to visualize the level and spread of the data. From a boxplot, you can see whether the data is symmetric or not, and how widely the data are spread. A box-whisker plot may be created with the `boxplot` function in the `matplotlib` package. As an example, a boxplot is drawn for 500 values drawn from a Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd.seed(10)\n",
    "data = rnd.normal(loc=10, scale=2, size=500)\n",
    "plt.boxplot(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `boxplot` function creates the graph and returns a lot of stuff such as 'boxes', 'caps', etc. These latter ones are handles to the different features of the graph; we will not use them here. What you see in the graph is a red line at the median of the data. The box spans the IQR ranging from the lower quartile (25%) to the upper quartile (75%). The whiskers are the black lines that are connected to the IQR box with black lines. They extend to the most extreme data point within the `whis*IQR` data range, where the default value of `whis` is 1.5. Any data points falling outside the whiskers are potential outliers and are plotted as little circles. In this case there are 5 points outside the whiskers, but none are outliers. They were, after all, drawn from the same Normal distribution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "All the techniques described in this Notebook can also be done with the `pandas` package. `pandas` is often much easier as it has a lot more functionality, it can handle missing values (`NaN` values, for example), and the plots look pretty by default.\n",
    "\n",
    "The `read_csv` function of `pandas` may be used to read data from a file and store it in a `DataFrame` (see `pandas` Notebook). In the example below, a `DataFrame` is created from scratch. First, the `pandas` package is imported and called `pd`. Then an empty `DataFrame` is created and values are added to two columns by drawing from two different normal distributions; the columns are called `test1` and `test2`. The `describe` function of `pandas` gives a nice summary of the data, including the number of values, mean, standard deviation, min, 25%, 50%, 75%, and max values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame()\n",
    "data['test1'] = rnd.normal(loc=3, scale=2, size=100)\n",
    "data['test2'] = rnd.normal(loc=5, scale=1, size=100)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values such as `mean` or `max` may be obtained for the entire `DataFrame` or for one column at a time. The quantiles may be obtained with the `quantile` function. The `quantile` function returns a DataFrame, which may be accessed using the standard functions for a `DataFrame`, or the values may be extracted into a `numpy` array using the `.values` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimum of test1:', data.test1.min())\n",
    "print('standard deviation of the DataFrame:')\n",
    "print(data.std())\n",
    "print('5% and 95% quantiles of test2:')\n",
    "print(data.test2.quantile([0.05, 0.95]))\n",
    "print('quantiles as numpy array:', data.test2.quantile([0.05, 0.95]).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of the data in two columns may be created with the `hist` function of `pandas`. Notice that the `sharex` and `sharey` keywords are set to `True` so that the horizontal and vertical axes have the same limits for both histograms (which facilitates comparison). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=(10, 4), density=True, sharex=True, sharey=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "Real data often contains missing values. Every database has its own way of treating missing values. Some databases leave the value empty, others substitute a number that can easily be recognized (for example -9999). In `pandas` these values need to be converted to NaNs (Not A Number). In the code below, the value with index 5 in the `test1` column is changed to `nan`. A cumulative histogram may be obtained as (Note: the `plt.hist` function doesn't work on data that includes NaN values, but the histogram function of `pandas` works like a charm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[5, 'test1'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[5, 'test1'] = np.nan  # Replace the value of test1 with index 5 to nan\n",
    "data.hist(cumulative=True, sharex=True, figsize=(10, 4), density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` also draws nice boxplots of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram or boxplot of one column of a DataFrame may be obtained by specifying the column you want to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "ax1 = plt.subplot(121)\n",
    "data.hist(column='test1', ax=ax1)  # Makes histogram of column test1\n",
    "ax2 = plt.subplot(122)\n",
    "data.boxplot(column='test2', ax=ax2);  # Makes boxplot of column test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique values in a DataFrame\n",
    "A useful `pandas` function is to determine the unique values in a DataFrame or in the column of a DataFrame.\n",
    "As an example, let's make a DataFrame with 100 random integers between 1 and 10. You can find out the unique values in the column with the '.unique()' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame()\n",
    "a['data'] = rnd.randint(1, 10 + 1, 100)\n",
    "print('unique values in data column:', a['data'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to start applying our statistical techniques to real data, rather than datasets generated with a random number generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src= \"http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Pseudotsuga_menziesii_28236.JPG/450px-Pseudotsuga_menziesii_28236.JPG\" width=\"200\" ALIGN=\"right\" style=\"padding:10px;\"> \n",
    "</figure>\n",
    "\n",
    "### Dataset of experiments on wooden beams\n",
    "A data set of 356 experiments on wooden beams, Douglas fir to be specific (see picture), is provided in the file `douglas_data.csv` (data courtesy Geert Ravenhorst, Timber Structures, Civil Engineering and Geosciences, TU Delft). The file contains 9 columns separated by commas. The first line (line number 0) of the file contains the names of the columns. The second line (line number 1) contains information about the units of the data (we won't load this information).  The first column has the name of the sample (`sample`), followed by: the moisture percentage (`moisture`), the knot ratio (`knotratio`), the tree ring width in mm (`treering`), the dynamic elasticity modulus in N/mm$^2$ (`Edyn`), the density of the wood in kg/m$^3$ (`density`), the beam height in mm (`beamheight`), the static elasticity modulus in N/mm$^2$ (`Estat`), and finally the bending strength in N/mm$^2$ (`bstrength`). A more extensive description of these different data is given when they are used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3. <a name=\"back3\"></a>Loading experimental data and basic operations\n",
    "Load the data in the file `douglas_data.csv` using the `read_csv` command of the `pandas` package (see the `pandas` Notebook if you forgot how). Use the `skiprows` and `skipinitialspace` keywords. Carry out the following three tasks:\n",
    "\n",
    "* Determine and report the minimum and maximum measured values of the bending strength. \n",
    "* Determine and report the mean and standard deviation of the density. \n",
    "* Determine and report the 0.25, 0.5, and 0.975 quantiles of the tree ring width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ex3answer\">Answers to Exercise 3</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4. <a name=\"back4\"></a>Boxplot of moisture content\n",
    "The moisture content is defined as the mass of moisture in a beam divided by the total mass of the beam (including the moisture) and is recorded as a percentage. Compute and report the mean and standard deviation of the moisture content, and make a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you look at the data, it is obvious that there is one outlier. Create a new boxplot for all the data except for the one outlier, for example by making a boxplot for all moisture data below a certain value. Make sure you choose correct limits for the vertical axis, so that the whiskers are visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ex4answer\">Answers to Exercise 4</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5. <a name=\"back5\"></a>Histogram of bending strength\n",
    "Create a histogram of the bending strength. Add labels to the axes. Does the histogram look like a Normal distribution? On the same graph draw a red vertical line for the experimentally determined 5% bending strength. Print the 0.05 experimental quantile bending strength to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ex5answer\">Answers to Exercise 5</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6. <a name=\"back6\"></a>Normal distribution for bending strength\n",
    "Let's try to fit a normal distribution to the bending strength data. This is obviously not quite correct, as the tail of the Normal distribution will extend below zero to the left, which is unrealistic. If the part of the tail below zero is small, it may be a reasonable first step. Create a normalized histogram of the bending strength. Compute the mean and standard deviation of the bending strength data and plot on the same graph the Normal probability density function using these estimates of the mean and standard deviation. Add a red vertical line for the 5% bending strength according to the data, and a black vertical line for the 5% bending strength according to the fitted Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ex6answer\">Answers to Exercise 6</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers to the exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex1answer\">Answers to Exercise 1</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "mu = 100\n",
    "sig = 10\n",
    "data = rnd.normal(loc=mu, scale=sig, size=1000)\n",
    "print('mean of data is:', np.mean(data))\n",
    "print('standard deviation of data is:', np.std(data))\n",
    "plt.subplot(211)\n",
    "a = plt.hist(data, bins=20, range=(50, 150), density=True)\n",
    "x = np.linspace(50, 150, 100)\n",
    "y = norm.pdf(x, loc=mu, scale=sig)\n",
    "plt.plot(x, y, 'r')\n",
    "plt.xlim(50, 150)\n",
    "plt.ylabel('probability')\n",
    "plt.subplot(212)\n",
    "b = plt.hist(data, bins=20, range=(50, 150), cumulative=True, \\\n",
    "             density=True, align='right')\n",
    "y = norm.cdf(x, mu, sig)\n",
    "plt.plot(x, y, 'r')\n",
    "plt.xlim(50, 150)\n",
    "plt.xlabel('bins')\n",
    "plt.ylabel('probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#back1\">Back to Exercise 1</a>\n",
    "\n",
    "<a name=\"ex2answer\">Answers to Exercise 2</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 20\n",
    "sig = 4\n",
    "p25, p75 = norm.ppf([0.25, 0.75], loc=mu, scale=sig)\n",
    "print('IQR pdf:', p25, p75)\n",
    "data = rnd.normal(loc=mu, scale=sig, size=100)\n",
    "d25, d75 = np.quantile(data, [0.25, 0.75])\n",
    "print('IQR of data ', d25, d75)\n",
    "plt.hist(data, bins=20, cumulative=True, density=True, align='right')\n",
    "plt.axvline(d25, color='r')\n",
    "plt.axvline(d75, color='r')\n",
    "plt.axvline(p25, color='k')\n",
    "plt.axvline(p75, color='k')\n",
    "plt.xlabel('bins')\n",
    "plt.ylabel('cumulative number of data points');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#back2\">Back to Exercise 2</a>\n",
    "\n",
    "<a name=\"ex3answer\">Answers to Exercise 3</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "w = read_csv('douglas_data.csv', skiprows=[1], skipinitialspace=True)\n",
    "print('min and max bending strength: ', w.bstrength.min(), w.bstrength.max())\n",
    "print('mean and std of density: ', w.density.mean(), w.density.std())\n",
    "print('2.5%, 50%, 97.5% tree ring width: ')\n",
    "print(w.treering.quantile([0.025, 0.5, 0.975]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#back3\">Back to Exercise 3</a>\n",
    "\n",
    "<a name=\"ex4answer\">Answers to Exercise 4</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean moisture content: ', w.moisture.mean())\n",
    "print('standard deviation of moisture content: ', w.moisture.std())\n",
    "a = plt.boxplot(w.moisture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(w.moisture[w.moisture < 30])\n",
    "plt.ylim(10.5, 17);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#back4\">Back to Exercise 4</a>\n",
    "\n",
    "<a name=\"ex5answer\">Answers to Exercise 5</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.hist(column='bstrength', density=True)\n",
    "plt.xlabel('bending strength (N/m$^2$)')\n",
    "five = w.bstrength.quantile(0.05)\n",
    "print('0.05 empirical quantile: ', five)\n",
    "plt.axvline(five, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#back5\">Back to Exercise 5</a>\n",
    "\n",
    "<a name=\"ex6answer\">Answers to Exercise 6</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "w.hist(column='bstrength', density=True)\n",
    "meanstrength = w.bstrength.mean()\n",
    "stdstrength = w.bstrength.std()\n",
    "x = np.linspace(0, 100, 100)\n",
    "y = norm.pdf(x, loc=meanstrength, scale=stdstrength)\n",
    "plt.plot(x, y, 'r')\n",
    "plt.axvline(five, color='r')\n",
    "plt.axvline(meanstrength - 1.64 * stdstrength, color='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#back6\">Back to Exercise 6</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
